```{julia}
#| echo: false
#| output: false
using Pkg
Pkg.activate("env/bayesian-mortality")
Pkg.instantiate()
```

:::callout-important
## Drafting Notes

Ideas: 
- First plot graph of outcomes and discuss some key features:
  - More variance when the subset are smaller

- Just plot the data first, with the group colors, to explain what we are looking at and for consistency in subsequent plots

- Generate sample data using parameters sampled from chain and show the bands on the associated outcomes.
:::


# Bayesian Mortality Modeling {#sec-bayesian-mortality}

## Generating fake data

The problem of interest is to look at mortality rates, which are given in terms of exposures (whether or not a life experienced a death in a given year).

We'll grab some example rates from an insurance table, which has a "selection" component: When someone enters observation, say at age 50, their mortality is path dependent (so for someone who started being observed at 50 will have a different risk/mortality rate at age 55 than someone who started being observed at 45).

Addtionally, there may be additional groups of interest, such as:

- high/medium/low risk classification
- sex
- group (e.g. company, data source, etc.)
- type of insurance product offered

The example data will start with only the risk classification above.
"""

```{julia}
using MortalityTables
using Turing
using UUIDs
using DataFramesMeta
using MCMCChains
using LinearAlgebra
using CairoMakie
```

```{julia}
src = MortalityTables.table("2001 VBT Residual Standard Select and Ultimate - Male Nonsmoker, ANB")

n = 10_000
```


```{julia}
function generate_data_individual(tbl, issue_age=rand(50:55), inforce_years=rand(1:30), risklevel=rand(1:3))
    # risk_factors will scale the "true" parameter up or down
    # we observe the assigned risklevel, but not risk_factor
    risk_factors = [0.7, 1.0, 1.5]
    rf = risk_factors[risklevel]
    deaths = rand(inforce_years) .< (tbl.select[issue_age][issue_age.+inforce_years.-1] .* rf)

    endpoint = if sum(deaths) == 0
        last(inforce_years)
    else
        findfirst(deaths)
    end
    id = uuid1()
    map(1:endpoint) do i
        (
            issue_age=issue_age,
            risklevel=risklevel,
            att_age=issue_age + i - 1,
            death=deaths[i],
            id=id,
        )
    end

end
```

```{julia}
exposures = vcat([generate_data_individual(src) for _ in 1:n]...) |> DataFrame

data = combine(groupby(exposures, [:issue_age, :att_age])) do subdf
    (exposures=nrow(subdf),
        deaths=sum(subdf.death),
        fraction=sum(subdf.death) / nrow(subdf))
end


# data2 = combine(groupby(exposures, [:issue_age, :att_age, :risklevel])) do subdf
#     (exposures=nrow(subdf),
#         deaths=sum(subdf.death),
#         fraction=sum(subdf.death) / nrow(subdf))
# end
```

## 1: A single binomial parameter model

Estiamte $q$, the average mortality rate, not accounting for any variation within the population/sample. Our model is defines as:

$$
q ~ Beta(1,1)
p(death) ~ Binomial(q)
$$

```{julia}
@model function mortality(data, deaths)
    q ~ Beta(1, 1)
    for i = 1:nrow(data)
        deaths[i] ~ Binomial(data.exposures[i], q)
    end
end

m1 = mortality(data, data.deaths)
```



### Sampling from the posterior

We use a No-U-Turn-Sampler (NUTS) technique to sample multile chains at once:

```{julia}
num_chains = 4
chain = sample(m1, NUTS(), MCMCThreads(), 400, num_chains)
```

Here, we have asked for the outcomes to be modeled via a single parameter for the population. We see that the posterior distirbution of $q$ is very close to the overall population mortality rate:

```{julia}
sum(data.deaths) / sum(data.exposures)
```

However, We can see that the sampling of possible posterior parameters doesn't really fit the data very well since our model was so simplified. The lines represent the posterior binomial probability.

This is saying that for the observed data, if there really is just a single probability `p` that governs the true process that came up with the data, there's a pretty narrow range of values it could possibly be:

```{julia}
let
    data_weight = log.(data.exposures)
    #data_weight = .√(data_weight ./ maximum(data_weight) .* 20)
    f = Figure(title="Parametric Bayseian Mortality"
    )
    ax = Axis(f[1, 1],
        xlabel="age",
        ylabel="mortality rate",
        # ylims=(0.0, 0.25),
    )
    scatter!(ax,
        data.att_age,
        data.fraction,
        markersize=data_weight,
        color=(:blue, 0.5),
        label="Experience data point (size indicates relative exposure quantity)",)

    # show n samples from the posterior plotted on the graph
    n = 300
    ages = sort!(unique(data.att_age))

    for i in 1:n
        p_posterior = sample(chain, 1)[:q][1]
        hlines!(ax, [p_posterior], color=(:grey, 0.1))
    end
    f
end
```



## 2. Parametric model

In this example, we utilize a [MakehamBeard](https://juliaactuary.github.io/MortalityTables.jl/stable/ParametricMortalityModels/#MortalityTables.MakehamBeard) parameterization because it's already very similar in form to a [logistic function](https://en.wikipedia.org/wiki/Logistic_function). This is important because our desired output is a probability (ie the probablity of a death at a given age), so the value must be constrained to be in the interval between zero and one.

The **prior** values for `a`,`b`,`c`, and `k` are chosen to constrain the hazard (mortality) rate to be between zero and one. 

This isn't an ideal parameterization (e.g. we aren't including information about the select underwriting period), but is an example of utilizing Bayesian techniques on life experience data.
"

```{julia}
@model function mortality2(data, deaths)
    a ~ Exponential(0.1)
    b ~ Exponential(0.1)
    c = 0.0
    k ~ truncated(Exponential(1), 1, Inf)

    # use the variables to create a parametric mortality model
    m = MortalityTables.MakehamBeard(; a, b, c, k)

    # loop through the rows of the dataframe to let Turing observe the data 
    # and how consistent the parameters are with the data
    for i = 1:nrow(data)
        age = data.att_age[i]
        q = MortalityTables.hazard(m, age)
        deaths[i] ~ Binomial(data.exposures[i], q)
    end
end
```

We combine the model with the data and sample from the posterior using a similar call as before:


```{julia}
m2 = mortality2(data, data.deaths)

chain2 = sample(m2, NUTS(), MCMCThreads(), 1000, num_chains)
```

summarize(chain2)

plot(chain2)

md"### Plotting samples from the posterior

We can see that the sampling of possible posterior parameters fits the data well:"

let
	data_weight = data.exposures ./ sum(data.exposures)
	data_weight = .√(data_weight ./ maximum(data_weight) .* 20)
	
	p = scatter(
		data.att_age,
		data.fraction, 
		markersize = data_weight, 
		alpha = 0.5, 
		label = "Experience data point (size indicates relative exposure quantity)",
		xlabel="age",
		ylim=(0.0,0.25),
		ylabel="mortality rate", 
		title="Parametric Bayseian Mortality"
	)
	

	# show n samples from the posterior plotted on the graph
	n = 300
	ages = sort!(unique(data.att_age))
	
	for i in 1:n
		s = sample(chain2,1)
		a = only(s[:a])
		b = only(s[:b])
		k = only(s[:k])
		c = 0
		m = MortalityTables.MakehamBeard(;a,b,c,k)
		plot!(ages,age -> MortalityTables.hazard(m,age), alpha = 0.1,label="")
	end
	p
end

```{julia}
let
    data_weight = log.(data.exposures)
    #data_weight = .√(data_weight ./ maximum(data_weight) .* 20)
    f = Figure(title="Parametric Bayseian Mortality"
    )
    ax = Axis(f[1, 1],
        xlabel="age",
        ylabel="mortality rate",
        # ylims=(0.0, 0.25),
    )
    scatter!(ax,
        data.att_age,
        data.fraction,
        markersize=data_weight,
        color=(:blue, 0.5),
        label="Experience data point (size indicates relative exposure quantity)",)

    # show n samples from the posterior plotted on the graph
    n = 300
    ages = sort!(unique(data.att_age))

    for i in 1:n
        s = sample(chain2, 1)
        a = only(s[:a])
        b = only(s[:b])
        k = only(s[:k])
        c = 0
        m = MortalityTables.MakehamBeard(; a, b, c, k)
        qs = MortalityTables.hazard.(m, ages)
        lines!(ax, ages, qs, color=(:grey, 0.1))
    end
    f
end
```

md"## 3. Parametric model

This model extends the prior to create a multi-level model. Each risk class (`risklevel`) gets its own $a$ paramater in the `MakhamBeard` model. The prior for $a_i$ is determined by the hyperparameter $\bar{a}$.
"

@model function mortality3(data,deaths) 
	risk_levels = length(levels(data.risklevel))
	b ~ Exponential(0.1)
	ā ~ Exponential(0.1)
	a ~ filldist(Exponential(ā), risk_levels)
	c = 0
	k ~ truncated(Exponential(1),1,Inf)
	
	# use the variables to create a parametric mortality model

	# loop through the rows of the dataframe to let Turing observe the data 
	# and how consistent the parameters are with the data
	for i = 1:nrow(data)
		risk = data.risklevel[i]
		
		m = MortalityTables.MakehamBeard(;a=a[risk],b,c,k)
		age = data.att_age[i]	
		q = MortalityTables.hazard(m,age)
		deaths[i] ~ Binomial(data.exposures[i],q)
	end
end

m3 = mortality3(data2,data2.deaths)

chain3 = sample(m3, NUTS(), 1000)

summarize(chain3)

PRECIS(DataFrame(chain3))

let data = data2
	
	data_weight = data.exposures ./ sum(data.exposures)
	data_weight = .√(data_weight ./ maximum(data_weight) .* 20)
	color_i = data.risklevel
	
	p = scatter(
		data.att_age,
		data.fraction, 
		markersize = data_weight, 
		alpha = 0.5, 
		color=color_i,
		label = "Experience data point (size indicates relative exposure quantity)",
		xlabel="age",
		ylim=(0.0,0.25),
		ylabel="mortality rate", 
		title="Parametric Bayseian Mortality"
	)
	

	# show n samples from the posterior plotted on the graph
	n = 100
	
	ages = sort!(unique(data.att_age))
	for r in 1:3	
		for i in 1:n
			s = sample(chain3,1)
			a = only(s[Symbol("a[$r]")])
			b = only(s[:b])
			k = only(s[:k])
			c = 0
			m = MortalityTables.MakehamBeard(;a,b,c,k)
			if i == 1 
				plot!(ages,age -> MortalityTables.hazard(m,age),label="risk level $r", alpha = 0.2,color=r)
			else
				plot!(ages,age -> MortalityTables.hazard(m,age),label="", alpha = 0.2,color=r)
			end
		end
	end
	p
end

md"## Handling non-unit exposures

The key is to use the Poisson distribution:
"

@model function mortality4(data,deaths) 
	risk_levels = length(levels(data.risklevel))
	b ~ Exponential(0.1)
	ā ~ Exponential(0.1)
	a ~ filldist(Exponential(ā), risk_levels)
	c ~ Beta(4,18)
	k ~ truncated(Exponential(1),1,Inf)
	
	# use the variables to create a parametric mortality model

	# loop through the rows of the dataframe to let Turing observe the data 
	# and how consistent the parameters are with the data
	for i = 1:nrow(data)
		risk = data.risklevel[i]
		
		m = MortalityTables.MakehamBeard(;a=a[risk],b,c,k)
		age = data.att_age[i]	
		q = MortalityTables.hazard(m,age)
		deaths[i] ~ Poisson(data.exposures[i] * q)
	end
end

m4 = mortality4(data2,data2.deaths)

chain4 = sample(m4, NUTS(), 1000)

PRECIS(DataFrame(chain4))

risk_factors4 = [mean(chain4[Symbol("a[$f]")]) for f in 1:3]

risk_factors4 ./ risk_factors4[2]

let data = data2
	
	data_weight = data.exposures ./ sum(data.exposures)
	data_weight = .√(data_weight ./ maximum(data_weight) .* 20)
	color_i = data.risklevel
	
	p = scatter(
		data.att_age,
		data.fraction, 
		markersize = data_weight, 
		alpha = 0.5, 
		color=color_i,
		label = "Experience data point (size indicates relative exposure quantity)",
		xlabel="age",
		ylim=(0.0,0.25),
		ylabel="mortality rate", 
		title="Parametric Bayseian Mortality"
	)
	

	# show n samples from the posterior plotted on the graph
	n = 100
	
	ages = sort!(unique(data.att_age))
	for r in 1:3	
		for i in 1:n
			s = sample(chain4,1)
			a = only(s[Symbol("a[$r]")])
			b = only(s[:b])
			k = only(s[:k])
			c = 0
			m = MortalityTables.MakehamBeard(;a,b,c,k)
			if i == 1 
				plot!(ages,age -> MortalityTables.hazard(m,age),label="risk level $r", alpha = 0.2,color=r)
			else
				plot!(ages,age -> MortalityTables.hazard(m,age),label="", alpha = 0.2,color=r)
			end
		end
	end
	p
end

md"## Predictions

We can generate predictive estimates by passing a vector of `missing` in place of the outcome variables and then calling `predict`. 

We get a table of values where each row is the the prediction implied by the corresponding chain sample, and the columns are the predicted value for each of the outcomes in our original dataset.
"

preds = predict(mortality4(data2,fill(missing,length(data2.deaths))),chain4)

size(preds)

```