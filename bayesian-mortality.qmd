# Bayesian Mortality Modeling {#sec-bayesian-mortality}

> “After a year of intense mental struggle, however, \[Arthur Bailey\] realized to his consternation that actuarial sledgehammering worked. He even preferred \[the Bayesian underpinnings of credibility theory\] to the elegance of frequentism. He positively liked formulae that described 'actual data. . . . I realized that the hard-shelled underwriters were recognizing certain facts of life neglected by the statistical theorists.' He wanted to give more weight to a large volume of data than to the frequentists’ small sample; doing so felt surprisingly 'logical and reasonable.' He concluded that only a 'suicidal' actuary would use Fisher’s method of maximum likelihood, which assigned a zero probability to nonevents.” - Excerpt From The Theory That Would Not Die Sharon Bertsch McGrayne

```{julia}
#| echo: false
#| output: false
using Pkg
Pkg.activate("env/bayesian-mortality")
Pkg.instantiate()
using Logging;
Logging.disable_logging(Logging.Warn);
```

::: callout-important
## Drafting Notes

Ideas: - First plot graph of outcomes and discuss some key features: - More variance when the subset are smaller

-   Just plot the data first, with the group colors, to explain what we are looking at and for consistency in subsequent plots

-   Generate sample data using parameters sampled from chain and show the bands on the associated outcomes.
:::

## In This Chapter

An example of using a Bayesian MCMC approach to fitting a mortality curve to sample data, with multi-level models and censored data.

## Generating fake data

The problem of interest is to look at mortality rates, which are given in terms of exposures (whether or not a life experienced a death in a given year).

We'll grab some example rates from an insurance table, which has a "selection" component: When someone enters observation, say at age 50, their mortality is path dependent (so for someone who started being observed at 50 will have a different risk/mortality rate at age 55 than someone who started being observed at 45).

Addtionally, there may be additional groups of interest, such as:

-   high/medium/low risk classification
-   sex
-   group (e.g. company, data source, etc.)
-   type of insurance product offered

The example data will start with only the risk classification above.

```{julia}
using MortalityTables
using Turing
using DataFramesMeta
using MCMCChains
using LinearAlgebra
using CairoMakie
using StatsBase
using OffsetArrays
```

```{julia}
n = 10_000
inforce = map(1:n) do i
    (
        issue_age=rand(30:70),
        risk_level=rand(1:3),
    )

end
```

```{julia}
base_table = MortalityTables.table("2001 VBT Residual Standard Select and Ultimate - Male Nonsmoker, ANB")

function tabular_mortality(params, issue_age, att_age, risk_level)
    q = params.ultimate[att_age]
    if risk_level == 1
        q *= 0.7
    elseif risk_level == 2
        q = q
    else
        q *= 1.5
    end
end
```

```{julia}
function model_outcomes(inforce, assumption, assumption_params; n_years=5)

    outcomes = map(inforce) do pol
        alive = 1
        sim = map(1:n_years) do t
            att_age = pol.issue_age + t - 1
            q = assumption(
                assumption_params,
                pol.issue_age,
                att_age,
                pol.risk_level
            )
            if rand() < q
                out = (att_age=att_age, exposures=alive, death=1)
                alive = 0
                out
            else
                (att_age=att_age, exposures=alive, death=0)
            end
        end
        filter!(x -> x.exposures == 1, sim)

    end


    df = DataFrame(inforce)

    df.outcomes = outcomes
    df = flatten(df, :outcomes)

    df.att_age = [x.att_age for x in df.outcomes]
    df.death = [x.death for x in df.outcomes]
    df.exposures = [x.exposures for x in df.outcomes]
    select!(df, Not(:outcomes))


end

exposures = model_outcomes(inforce, tabular_mortality, base_table)
data = combine(groupby(exposures, [:issue_age, :att_age])) do subdf
    (exposures=nrow(subdf),
        deaths=sum(subdf.death),
        fraction=sum(subdf.death) / nrow(subdf))
end


data2 = combine(groupby(exposures, [:issue_age, :att_age, :risk_level])) do subdf
    (exposures=nrow(subdf),
        deaths=sum(subdf.death),
        fraction=sum(subdf.death) / nrow(subdf))
end
```

## 1: A single binomial parameter model

Estiamte $q$, the average mortality rate, not accounting for any variation within the population/sample. Our model is defines as:

$$
q ~ Beta(1,1)
p(\text{death}) ~ \text{Binomial}(q)
$$

```{julia}
@model function mortality(data, deaths)
    q ~ Beta(1, 1)
    for i = 1:nrow(data)
        deaths[i] ~ Binomial(data.exposures[i], q)
    end
end

m1 = mortality(data, data.deaths)
```

### Sampling from the posterior

We use a No-U-Turn-Sampler (NUTS) technique to sample multiple chains at once:

```{julia}
num_chains = 4
chain = sample(m1, NUTS(), MCMCThreads(), 400, num_chains)
```

Here, we have asked for the outcomes to be modeled via a single parameter for the population. We see that the posterior distribution of $q$ is very close to the overall population mortality rate:

```{julia}
sum(data.deaths) / sum(data.exposures)
```

However, We can see that the sampling of possible posterior parameters doesn't really fit the data very well since our model was so simplified. The lines represent the posterior binomial probability.

This is saying that for the observed data, if there really is just a single probability `p` that governs the true process that came up with the data, there's a pretty narrow range of values it could possibly be:

```{julia}
let
    data_weight = sqrt.(data.exposures) /  2
    f = Figure(title="Parametric Bayseian Mortality"
    )
    ax = Axis(f[1, 1],
        xlabel="age",
        ylabel="mortality rate",
        limits=(nothing, nothing, -0.02, 0.25),
    )
    scatter!(ax,
        data.att_age,
        data.fraction,
        markersize=data_weight,
        color=(:blue, 0.5),
        label="Experience data point (size indicates relative exposure quantity)",)

    # show n samples from the posterior plotted on the graph
    n = 300
    ages = sort!(unique(data.att_age))

    q_posterior = sample(chain, n)[:q]


    for i in 1:n

        hlines!(ax, [q_posterior[i]], color=(:grey, 0.1))
    end

    # Need to simulate at indivudal level and then aggregate?


    sim05 = Float64[]
    sim95 = Float64[]
    for r in eachrow(data)
        outcomes = map(1:n) do i
            rand(Binomial(r.exposures, q_posterior[i]), 500)
        end
        push!(sim05, quantile(Iterators.flatten(outcomes), 0.05) / r.exposures)
        push!(sim95, quantile(Iterators.flatten(outcomes), 0.95) / r.exposures)


    end



    f
end
```

```{julia}
let
    n = 300
    q_posterior = sample(chain, n)[:q]


end
```

## 2. Parametric model

In this example, we utilize a [MakehamBeard](https://juliaactuary.github.io/MortalityTables.jl/stable/ParametricMortalityModels/#MortalityTables.MakehamBeard) parameterization because it's already very similar in form to a [logistic function](https://en.wikipedia.org/wiki/Logistic_function). This is important because our desired output is a probability (ie the probability of a death at a given age), so the value must be constrained to be in the interval between zero and one.

The **prior** values for `a`,`b`,`c`, and `k` are chosen to constrain the hazard (mortality) rate to be between zero and one.

This isn't an ideal parameterization (e.g. we aren't including information about the select underwriting period), but is an example of utilizing Bayesian techniques on life experience data. "

```{julia}
@model function mortality2(data, deaths)
    a ~ Exponential(0.1)
    b ~ Exponential(0.1)
    c = 0.0
    k ~ truncated(Exponential(1), 1, Inf)

    # use the variables to create a parametric mortality model
    m = MortalityTables.MakehamBeard(; a, b, c, k)

    # loop through the rows of the dataframe to let Turing observe the data 
    # and how consistent the parameters are with the data
    for i = 1:nrow(data)
        age = data.att_age[i]
        q = MortalityTables.hazard(m, age)
        deaths[i] ~ Binomial(data.exposures[i], q)
    end
end
```

We combine the model with the data and sample from the posterior using a similar call as before:

```{julia}
m2 = mortality2(data, data.deaths)

chain2 = sample(m2, NUTS(), MCMCThreads(), 400, num_chains)
```

### Plotting samples from the posterior

We can see that the sampling of possible posterior parameters fits the data well:

```{julia}
let
    data_weight = sqrt.(data.exposures) / 2

    p = scatter(
        data.att_age,
        data.fraction,
        markersize=data_weight,
        alpha=0.5,
        label="Experience data point (size indicates relative exposure quantity)",
        axis=(
            xlabel="age",
            limits=(nothing, nothing, -0.02, 0.25),
            ylabel="mortality rate",
            title="Parametric Bayseian Mortality"
        )
    )


    # show n samples from the posterior plotted on the graph
    n = 300
    ages = sort!(unique(data.att_age))

    for i in 1:n
        s = sample(chain2, 1)
        a = only(s[:a])
        b = only(s[:b])
        k = only(s[:k])
        c = 0
        m = MortalityTables.MakehamBeard(; a, b, c, k)
        lines!(ages, age -> MortalityTables.hazard(m, age), alpha=0.1, label="")
    end
    p
end
```

```{julia}
let
    data_weight = sqrt.(data.exposures) / 2
    f = Figure(title="Parametric Bayseian Mortality"
    )
    ax = Axis(f[1, 1],
        xlabel="age",
        ylabel="mortality rate",
        limits=(nothing, nothing, -0.02, 0.25),
    )
    scatter!(ax,
        data.att_age,
        data.fraction,
        markersize=data_weight,
        color=(:blue, 0.5),
        label="Experience data point (size indicates relative exposure quantity)",)

    # show n samples from the posterior plotted on the graph
    n = 300
    ages = sort!(unique(data.att_age))

    for i in 1:n
        s = sample(chain2, 1)
        a = only(s[:a])
        b = only(s[:b])
        k = only(s[:k])
        c = 0
        m = MortalityTables.MakehamBeard(; a, b, c, k)
        qs = MortalityTables.hazard.(m, ages)
        lines!(ax, ages, qs, color=(:grey, 0.1))
    end
    f
end
```

## 3. Parametric model

This model extends the prior to create a multi-level model. Each risk class (`risk_level`) gets its own $a$ paramater in the `MakhamBeard` model. The prior for $a_i$ is determined by the hyper-parameter $\bar{a}$.

```{julia}
@model function mortality3(data, deaths)
    risk_levels = length(levels(data.risk_level))
    b ~ Exponential(0.1)
    ā ~ Exponential(0.1)
    a ~ filldist(Exponential(ā), risk_levels)
    c = 0
    k ~ truncated(Exponential(1), 1, Inf)

    # use the variables to create a parametric mortality model

    # loop through the rows of the dataframe to let Turing observe the data 
    # and how consistent the parameters are with the data
    for i = 1:nrow(data)
        risk = data.risk_level[i]

        m = MortalityTables.MakehamBeard(; a=a[risk], b, c, k)
        age = data.att_age[i]
        q = MortalityTables.hazard(m, age)
        deaths[i] ~ Binomial(data.exposures[i], q)
    end
end

m3 = mortality3(data2, data2.deaths)

chain3 = sample(m3, NUTS(), 1000)

summarize(chain3)
```

```{julia}
let data = data2

    data_weight = sqrt.(data.exposures) / 2
    color_i = data.risk_level

    p = scatter(
        data.att_age,
        data.fraction,
        markersize=data_weight,
        alpha=0.5,
        color=color_i,
        label="Experience data point (size indicates relative exposure quantity)",
        axis=(
            xlabel="age",
            limits=(nothing, nothing, -0.02, 0.25),
            ylabel="mortality rate",
            title="Parametric Bayseian Mortality"
        )
    )


    # show n samples from the posterior plotted on the graph
    n = 100

    ages = sort!(unique(data.att_age))
    for r in 1:3
        for i in 1:n
            s = sample(chain3, 1)
            a = only(s[Symbol("a[$r]")])
            b = only(s[:b])
            k = only(s[:k])
            c = 0
            m = MortalityTables.MakehamBeard(; a, b, c, k)
            if i == 1
                lines!(ages, age -> MortalityTables.hazard(m, age), label="risk level $r", alpha=0.2, color=(CairoMakie.Makie.wong_colors()[r], 0.2))
            else
                lines!(ages, age -> MortalityTables.hazard(m, age), label="", alpha=0.2, color=(CairoMakie.Makie.wong_colors()[r], 0.2))
            end
        end
    end
    p
end
```

## Handling non-unit exposures

The key is to use the Poisson distribution, which is a continuous approximation to the Binomial distribution:

```{julia}
@model function mortality4(data, deaths)
    risk_levels = length(levels(data.risk_level))
    b ~ Exponential(0.1)
    ā ~ Exponential(0.1)
    a ~ filldist(Exponential(ā), risk_levels)
    c ~ Beta(4, 18)
    k ~ truncated(Exponential(1), 1, Inf)

    # use the variables to create a parametric mortality model

    # loop through the rows of the dataframe to let Turing observe the data 
    # and how consistent the parameters are with the data
    for i = 1:nrow(data)
        risk = data.risk_level[i]

        m = MortalityTables.MakehamBeard(; a=a[risk], b, c, k)
        age = data.att_age[i]
        q = MortalityTables.hazard(m, age)
        deaths[i] ~ Poisson(data.exposures[i] * q)
    end
end

m4 = mortality4(data2, data2.deaths)

chain4 = sample(m4, NUTS(), 1000)
```

```{julia}
risk_factors4 = [mean(chain4[Symbol("a[$f]")]) for f in 1:3]

risk_factors4 ./ risk_factors4[2]

let data = data2

     data_weight = sqrt.(data.exposures) / 2
    color_i = data.risk_level

    p = scatter(
        data.att_age,
        data.fraction,
        markersize=data_weight,
        alpha=0.5,
        color=color_i,
        label="Experience data point (size indicates relative exposure quantity)",
        axis=(xlabel="age",
            limits=(nothing, nothing, -0.02, 0.25),
            ylabel="mortality rate",
            title="Parametric Bayseian Mortality"
        )
    )


    # show n samples from the posterior plotted on the graph
    n = 100

    ages = sort!(unique(data.att_age))
    for r in 1:3
        for i in 1:n
            s = sample(chain4, 1)
            a = only(s[Symbol("a[$r]")])
            b = only(s[:b])
            k = only(s[:k])
            c = 0
            m = MortalityTables.MakehamBeard(; a, b, c, k)
            if i == 1
                lines!(ages, age -> MortalityTables.hazard(m, age), label="risk level $r", alpha=0.2, color=(CairoMakie.Makie.wong_colors()[r], 0.2))
            else
                lines!(ages, age -> MortalityTables.hazard(m, age), label="", alpha=0.2, color=(CairoMakie.Makie.wong_colors()[r], 0.2))
            end
        end
    end
    p
end
```

## Model Predictions

We can generate predictive estimates by passing a vector of `missing` in place of the outcome variables and then calling `predict`.

We get a table of values where each row is the the prediction implied by the corresponding chain sample, and the columns are the predicted value for each of the outcomes in our original dataset.

```{julia}
preds = predict(mortality4(data2, fill(missing, length(data2.deaths))), chain4)
```