---
author:
  - name: Alec Loudenback
---

# Why use Julia?

> We want a language that's open source, with a liberal license. We want the speed of C with the dynamism of Ruby. We want a language that's homoiconic, with true macros like Lisp, but with obvious, familiar mathematical notation like Matlab. We want something as usable for general programming as Python, as easy for statistics as R, as natural for string processing as Perl, as powerful for linear algebra as Matlab, as good at gluing programs together as the shell. Something that is dirt simple to learn, yet keeps the most serious hackers happy. We want it interactive and we want it compiled. - Bezanson, Karpinski, Shaw, Edelman (the original creators of Julia)

## Chapter Overview

Why Julia? Because it's fast, expressive, and designed for the kind of work financial modelers actually do.

## Introduction

Julia`\index{Julia}`{=latex} is a relatively new[^why-julia-1], productive, and fast programming language. This is evident in its pragmatic, productivity-focused design choices, pleasant syntax, rich ecosystem, thriving communities, and its ability to be both very general purpose and power cutting-edge computing.

[^why-julia-1]: Python first appeared in 1990. R is an implementation of S, which was created in 1976, though depending on when you want to place the start of an independent R project varies (1993, 1995, and 2000 are alternate dates). The history of these languages is long and substantial changes have occurred since these dates.

With Julia: math-heavy code looks like math; it's easy to pick up, and quick to prototype. Packages are well-integrated, with excellent visualization libraries and pragmatic design choices.

Julia's popularity continues to grow across many fields, with a growing body of online references, tutorials, videos, and print media to learn from.

Large financial services organizations have already started realizing gains: BlackRock's Aladdin portfolio modeling, the Federal Reserve's economic simulations, and Aviva's Solvency II-compliant modeling[^why-julia-2]. The last of these has a [great talk on YouTube](https://www.youtube.com/watch?v=__gMirBBNXY) by Aviva's Tim Thornham that showcases an on-the-ground view of what difference the right choice of technology and programming language can make. Moving from their vendor-supplied modeling solution was **1000x faster, took 1/10 the amount of code, and was implemented 10x faster**.

[^why-julia-2]: [Aviva Case Study](https://juliacomputing.com/case-studies/aviva.html)

The language is great for data science, but also for modeling, ETL, visualizations, package management, machine learning, string manipulation, web-backends, and many other use cases.

Julia is well suited for financial modeling work: easy to read and write and very performant.

::: callout-tip
**The two language problem**`\index{two language problem}`{=latex} is a term describing processes and teams that separate "domain expertise" coding from "production" coding. This isn't always a "problem", but the "two language problem" describes the scenario where this arises not out of intention but out of the necessity of dealing with limitations of the programming languages used. The most common combination is when the domain experts utilize Python, while the quants or developers write C++. This arises because the productive, high level language hits a barrier in terms of speed, efficiency, and robustness. Then, as a necessary step to achieve the end goals of the business, the domain experts hand off the logic to be re-implemented into the lower level language. Not only does this effectively limit the architecture, it essentially defines a required staffing model which may introduce a lot of cost and redundancy in expertise. Julia solves this to a large extent, allowing for a high level, productive language to be very fast.

A similar, related dichotomy is the **two culture problem**`\index{two culture problem}`{=latex} wherein domain experts (e.g. financial analysts) exist in a different sphere from developers. This manifests in many ways, such as restricting the tools that each group is permitted to use (e.g. Excel for domain experts, codebases and Git for developers). This is less of a technical problem and more of a social one. However, Julia is also one of the better languages in this regard, because much of the associated tooling is made as straightforward as possible (e.g. packaging, distribution, workflows, etc.). See @sec-software-principles and @sec-julia-writing through @sec-julia-optimizing for more on this.
:::

## Julia and This Book

Julia is introduced only insofar as a basic understanding is necessary to illustrate certain concepts. Julia is ideal here because it's generally straightforward and concise, letting the presented idea have the spotlight (as opposed to language boilerplate or obtuse keywords). The point of this structure is to introduce a wide variety of computer science concepts to the financial professional, *not* to introduce Julia as a programming language (there are many other resources that do that just fine).

This chapter motivates why we choose Julia for teaching and for work. In @sec-elements-programming, we introduce core language concepts and syntax. After that, the content focuses on illustrating key concepts, with Julia taking a secondary role as backdrop. It's not until @sec-julia-writing that Julia regains the spotlight for particulars that matter mainly to heavy Julia users.

## Expressiveness and Syntax

**Expressiveness**`\index{expressiveness}`{=latex} is the *manner in which* and *scope of* ideas and concepts that can be represented in a programming language. **Syntax**`\index{syntax}`{=latex} refers to how the code *looks* on the screen and its readability.

In a language with high expressiveness and pleasant syntax, you:

-   Go from idea in your head to final product faster.
-   Encapsulate concepts naturally and write concise functions.
-   Compose functions and data naturally.
-   Focus on the end-goal instead of fighting the tools.

Expressiveness can be hard to explain, but perhaps two short examples will illustrate.

### Example 1: Retention Analysis

This is a really simple example relating `Cession`s, `Policy`s, and `Life`s to do simple retention analysis. Retention is a measure of how much risk an insurance company holds on a policy after its own reinsurance risk transfer (ceded amounts of coverage are called "cessions").

First, let's define our data:

```{julia}

# Define our data structures
struct Life
    policies
end

struct Policy
    face
    cessions
end

struct Cession
    ceded
end
```

Now to calculate amounts retained. First, let's say what retention means for a `Policy`:

```{julia}
# define retention
function retained(pol::Policy)
    pol.face - sum(cession.ceded for cession in pol.cessions)
end
```

And then what retention means for a `Life`:

```{julia}
function retained(l::Life)
    sum(retained(policy) for policy in l.policies)
end
```

It's almost exactly how you'd specify it in English. No joins, no boilerplate, no fiddling with complicated syntax. You express ideas the way you think of them—not as a series of dataframe joins or row/column coordinates on a spreadsheet.

We defined `retained` and adapted it to mean related but different things depending on the context. We didn't have to define `retained_life(...)` and `retained_pol(...)` because Julia can **dispatch**`\index{multiple dispatch}`{=latex} based on what you give it (this is a more powerful, generalized version of method dispatch commonly used in object-oriented programming; see @sec-data-types for more).

Let's use the above code in practice.

```{julia}
#| code-overflow: wrap
# create two policies with two and one cessions respectively
pol_1 = Policy(1000, [Cession(100), Cession(500)])
pol_2 = Policy(2500, [Cession(1000)])

# create a life, which has the two policies
life = Life([pol_1, pol_2])
```

```{julia}
retained(pol_1)
```

```{julia}
retained(life)
```

Finally, something called "broadcasting"`\index{broadcasting}`{=latex}, which automatically vectorizes any function you write over the given collection(s), no need to write loops or create `if` statements to handle a single vs repeated case:

```{julia}
retained.(life.policies) # retained amount for each policy
```

### Example 2: Random Sampling

As another motivating example showcasing multiple dispatch, here's random sampling in Julia, R, and Python.

We generate 100 of each:

-   Uniform random numbers
-   Standard normal random numbers
-   Bernoulli random numbers
-   Random samples with a given set

::: landscape
+-------------------------------------+-----------------------------------+--------------------------------------------+
| Julia                               | R                                 | Python                                     |
+=====================================+===================================+============================================+
| ``` julia                           | ``` r                             | ``` python                                 |
| using Distributions                 | runif(100)                        | import scipy.stats as sps                  |
|                                     | rnorm(100)                        | import numpy as np                         |
| rand(100)                           | rbinom(100, 1, 0.5)              |                                            |
| rand(Normal(), 100)                 | sample(c("Preferred","Standard"), |                                            |
| rand(Bernoulli(0.5), 100)           | 100, replace=TRUE)                | sps.uniform.rvs(size=100)                  |
| rand(["Preferred","Standard"], 100) | ```                               | sps.norm.rvs(size=100)                     |
| ```                                 |                                   | sps.bernoulli.rvs(p=0.5,size=100)          |
|                                     |                                   | np.random.choice(["Preferred","Standard"], |
|                                     |                                   | size=100)                                  |
|                                     |                                   | ```                                        |
+-------------------------------------+-----------------------------------+--------------------------------------------+

: A comparison of random outcome generation in Julia, R, and Python. {#tbl-code-compare}
:::

In Julia, rand dispatches on the argument’s type: arrays, distributions, and collections all work with the same function, illustrating multiple dispatch. By understanding the different types of things passed to `rand()`, it maintains the same syntax across a variety of different scenarios. We could define `rand(Cession)` and have it generate a random `Cession` like we used above.

## The Speed

As stated in the [journal Nature](https://www.nature.com/articles/d41586-019-02310-3), "Come for the Syntax, Stay for the Speed".

Earlier we described Aviva's Solvency II compliance modeling, which ran 1000x faster than the prior vendor solution: what does it mean to be 1000x faster at something? It's the difference between something taking 10 seconds instead of 3 hours — or 1 hour instead of 42 days.

With this difference in speed, you would be able to complete existing processes much faster, or extend the analysis further. This speed could allow you to do new things: a stochastic analysis of life-level claims, machine learning with your experience data, or perform much more frequent valuation.

Here's a real example, comparing the runtime to calculate the price of a vanilla European call option using the Black-Scholes-Merton formula`\index{Black-Scholes-Merton formula}`{=latex}, as well as the associated code for each. Here's the mathematical formula we are using:

$$
\begin{aligned}
\text{Call}(S_t, t) &= N(d_1)S_t - N(d_2)Ke^{-r(T - t)} \\
d_1 &= \frac{1}{\sigma\sqrt{T - t}}\left[\ln\left(\frac{S_t}{K}\right) + \left(r + \frac{\sigma^2}{2}\right)(T - t)\right] \\
d_2 &= d_1 - \sigma\sqrt{T - t}
\end{aligned}
$$

``` julia
using Distributions

function d1(S,K,τ,r,σ)
    (log(S/K) + (r + σ^2/2) * τ) / (σ * √(τ))
end

function d2(S,K,τ,r,σ)
    d1(S,K,τ,r,σ) - σ * √(τ)
end

function Call(S,K,τ,r,σ)
    N(x) = cdf(Normal(),x)
    d₁ = d1(S,K,τ,r,σ)
    d₂ = d2(S,K,τ,r,σ)
    return N(d₁)*S - N(d₂) * K * exp(-r*τ)
end

S,K,τ,σ,r = 300, 250, 1, 0.15, 0.03

Call(S,K,τ,r,σ) # 58.81976813699322
```

``` python
from scipy import stats
import math

def d1(S,K,τ,r,σ):
    return (math.log(S/K) + (r + σ**2/2) * τ) / (σ * math.sqrt(τ))

def d2(S,K,τ,r,σ):
    return d1(S,K,τ,r,σ) - σ * math.sqrt(τ)

def Call(S,K,τ,r,σ):
    N = lambda x: stats.norm().cdf(x)
    d_1 = d1(S,K,τ,r,σ)
    d_2 = d2(S,K,τ,r,σ)
    return N(d_1)*S - N(d_2) * K * math.exp(-r*τ)

S = 300
K = 250
τ = 1
σ = 0.15
r = 0.03

Call(S,K,τ,r,σ) # 58.81976813699322
```

``` r
d1<- function(S,K,t,r,sig) {
  ans <- (log(S/K) + (r + sig^2/2)*t) / (sig*sqrt(t))
  return(ans)
} 

d2 <- function(S,K,t,r,sig) {
  return(d1(S,K,t,r,sig) - sig*sqrt(t))
}

Call <- function(S,K,t,r,sig) {
  d_1 <- d1(S,K,t,r,sig)
  d_2 <- d2(S,K,t,r,sig)
  return(S*pnorm(d_1) - K*exp(-r*t)*pnorm(d_2))
}
S <- 300
K <- 250
t <- 1
r <- 0.03
sig <- 0.15

Call(S,K,t,r,sig) # 58.81977
```

We find in @tbl-bsm-benchmark that, despite the syntactic similarity, Julia is much faster than the other two. Exact numbers vary by hardware and implementation choices; the key point is that you can write high-level Julia and still get C-like performance.

+-----------+------------------------------+----------------------+---------------+
| Language  | Median *(nanoseconds)*       | Mean *(nanoseconds)* | Relative Mean |
+===========+==============================+======================+===============+
| Python    | N/A                          | 817000.0             | 19926.0       |
+-----------+------------------------------+----------------------+---------------+
| R         | 3649.0                       | 3855.2               | 92.7          |
+-----------+------------------------------+----------------------+---------------+
| Julia     | 41.0                         | 41.6                 | 1.0           |
+-----------+------------------------------+----------------------+---------------+

: On our test machine, a scalar BSM pricing function implemented in idiomatic Julia ran in tens of nanoseconds per call after JIT warmup. Comparable R code ran in a few microseconds, and a pure-Python version (without vectorized NumPy) ran orders of magnitude slower. Python's `timeit` library does not calculate the median, so it is not available. {#tbl-bsm-benchmark}

### Development Speed

Speed is not just great for improvement in production processes. During development, it’s really helpful too. When building something, the faster feedback loop allows for more productive development. The build, test, fix, iteration cycle goes faster this way.

Admittedly, most workflows don't see a 1000x speedup, but 10x to 1000x is a very common range of speed differences versus R, Python, or MATLAB.

::: callout-note
Sometimes you will see less of a speed difference; R and Python have already circumvented this and written much core code in low-level languages. This is what's called the "two-language" problem where the language productive to write in isn't very fast. For example, [more than half of R packages use C/C++/Fortran](https://developer.r-project.org/Blog/public/2019/03/28/use-of-c---in-packages/) and core packages in Python like Pandas, PyTorch, NumPy, SciPy, etc. do this too.

Within the bounds of the optimized R/Python libraries, you can leverage this work. Extending it can be difficult. What if you have a custom retention management system running on millions of policies every night? In technical terms, libraries like NumPy are not able to handle custom data types, and instead limit use to pre-built types within the library. In contrast, all types in Julia are effectively equal, even ones that you might create yourself.

Julia packages you are using are almost always written in pure Julia: you can see what's going on, learn from them, or even contribute a package of your own!
:::

## More of Julia's benefits

Julia is easy to write, learn, and be productive in:

-   It's free and open-source
    -   Very permissive licenses, facilitating the use in commercial environments (same with most packages)
-   Large and growing set of available packages
-   Write how you like because it's multi-paradigm: vector-izable (R), object-oriented (Python), functional (Lisp), or detail-oriented (C)
-   Built-in package manager, documentation, and testing library
-   Jupyter Notebook`\index{Jupyter notebooks}`{=latex} support (it's in the name! **Ju**lia-**Pyt**hon-**R**)
-   Many small, nice things that add up:
    -   Unicode characters like `α` or `β`
    -   Nice display of arrays
    -   Simple anonymous function syntax
    -   Wide range of text editor support
    -   First-class support for missing values across the entire language
    -   Literate programming support (like R-Markdown)
-   Built-in `Dates` package that makes working with dates pleasant
-   Ability to directly call and use R and Python code/packages with the [`PythonCall.jl`](https://github.com/JuliaPy/PythonCall.jl) and [RCall](https://github.com/JuliaInterop/RCall.jl) packages
-   Error messages are helpful and tell you *what line* the error came from, not just the type of error
-   Debugger functionality so you can step through your code line by line

For power-users, advanced features are easily accessible: parallel programming, broadcasting, types`\index{type system}`{=latex}, interfaces, metaprogramming, and more.

These are some of the things that make Julia one of the world's most loved languages on the [StackOverflow Developer Survey](https://insights.stackoverflow.com/survey/2020#technology-most-loved-dreaded-and-wanted-languages).

In addition to the liberal licensing mentioned above, there are professional products from organizations like [JuliaHub](https://juliahub.com/)`\index{JuliaHub}`{=latex} that provide hands-on support, training, IT governance solutions, behind-the-firewall package management, and deployment/scaling assistance.

## Tradeoffs when Using Julia

### Just-In-Time Compilation

Julia is fast because it's compiled, unlike R and Python where (loosely speaking) the computer reads one line at a time. Julia compiles code "just-in-time" (JIT)`\index{just-in-time compilation}`{=latex}: right before you use a function for the first time, it takes a moment to pre-process the code for the machine[^why-julia-3]. Subsequent calls don't need re-compilation and are very fast.

[^why-julia-3]: Julia can also precompile code ahead of time to avoid the latency involved with running a function for the first time each time a Julia session is started.

A hypothetical example: running 10,000 stochastic projections where Julia needs to precompile but then runs each 10x faster:

-   Julia runs in 2 minutes: the first projection takes 1 second to compile and run; the remaining 9,999 projections only take 10 ms.
-   Python runs in 17 minutes: 100 ms for each computation.

Typically, compilation is very fast (milliseconds), but in the most complicated cases it can be several seconds. The most common example is the "time-to-first-plot"`\index{time-to-first-plot}`{=latex} issue: super-flexible plotting libraries have a lot to precompile. It can take several seconds to display the first plot after starting Julia, but then it's remarkably quick and easy to create an animation of your model results (which requires repeated evaluation of the plot). This is a solvable problem receiving attention from core developers and is improving with new Julia releases.

For users working with a lot of data or complex calculations (like actuaries!), the runtime speedup is worth a few seconds at the start.

### Static Binaries

Static binaries are self-contained executable programs that run specific code. They compile down to small binaries that accomplish just their pre-programmed tasks. Another use case is creating shared libraries callable from other languages. You can create self-contained artifacts via PackageCompiler.jl that bundle the Julia runtime; truly minimal static binaries are an active area of research.

Julia's dynamic nature means it needs to include supporting infrastructure to run general code, similar to how Python code needs the Python runtime bundled.

Development is happening at the language level to allow Julia to compile to a smaller, more static set of features for memory-constrained environments.

## Package Ecosystem

Julia's bundled package manager`\index{package manager}`{=latex} helps with using packages as dependencies in your project.

For each project, you can track the exact set of dependencies and replicate the code on another machine or at another time. In R or Python, dependency management`\index{dependency management}`{=latex} is notoriously difficult and it's one of the things the Julia creators wanted to fix from the start.

There are thousands of publicly available packages already published. It's also straightforward to share privately, such as proprietary packages hosted internally behind a firewall.

Another powerful aspect of the package ecosystem is that due to the language design, packages can be combined/extended in ways that are difficult for other common languages. This means that Julia packages are often interoperable without any additional coordination.

For example, packages that operate on data tables work together without issue in Julia. In R/Python, many features tend to come bundled in a giant singular package like Python's Pandas, which has Input/Output, date manipulation, plotting, resampling, and more. There’s a new Consortium for Python Data API Standards which seeks to harmonize the different packages in Python to make them more consistent (R’s Tidyverse plays a similar role in coordinating their subset of the package ecosystem).

In Julia, packages tend to be more plug-and-play. For example, every time you load a CSV you might not want a dataframe (maybe you want a matrix or a plot instead). To load data into a dataframe, the Julia practice is to use both the CSV and DataFrames packages, separating concerns and composing dependencies as necessary. Some users may prefer the Python/R approach of less modular but more all-inclusive packages.

## Tools in Your Toolbox

Looking at other great tools like R and Python, it's difficult to summarize a single reason to switch to Julia—but hopefully we've piqued your interest and can now turn to important concepts.

That said, Julia shouldn't be the only tool in your toolkit. SQL will remain an important way to interact with databases. R and Python aren't going anywhere and will always offer different perspectives!

Being a productive financial professional means being proficient in the language of computers so you can build and implement great things. The choice of tools and paradigms shapes your focus. Productivity is one aspect, expressiveness another, speed one more. Trying out different tools is probably the best way to find what works for you. Julia's multiple-dispatch design lets you write generic models while still hitting performance targets. Combined with GPU acceleration and packages like CUDA.jl, Optimization.jl, ModelingToolkit.jl, and DifferentialEquations.jl, you can solve large stochastic, PDE, or optimal control problems without switching languages. This is why shops like BlackRock, Aviva, and the Federal Reserve increasingly turn to Julia for portfolio analytics, ALM, and macroeconomic modeling.

### Interoperability

Julia isn't an island: PythonCall.jl`\index{PythonCall.jl}`{=latex} lets you call Python packages seamlessly; RCall.jl`\index{RCall.jl}`{=latex} does the same for R. This interoperability`\index{interoperability}`{=latex} allows gradual migration. You can keep mission-critical models written in other ecosystems while gradually migrating performance-sensitive components. Libraries like Arrow.jl, Parquet.jl, and ODBC.jl connect Julia with data warehouses and BI tools. In practice, you can move incrementally: wrap legacy C++ or Python risk engines, pilot new analytics in pure Julia, and phase out old code only when you're satisfied with the results.