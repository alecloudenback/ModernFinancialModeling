# Stochastic Mortality Projections {#sec-stochastic-mortality}

## In This Chapter

A term life insurance policy is used to illustrate: selecting key model features, design tradeoffs between a few different approaches, and a discussion of the performance impacts of the different approaches to parallelism.

```{julia}
#| echo: false
#| output: false
using Pkg
Pkg.activate("env/stochastic_mortality")
Pkg.instantiate()
```

## Introduction

Monte Carlo simulation is common in risk and valuation contexts. This worked example will create a population of term life insurance policies and simulate the associated claims stochastically. For this chapter, the focus is not so much on the outcomes of the model, but instead *how* and *why* the model was chosen to be setup in the way that it is.

The general structure of the example is:

1.  Define the datatypes and sample data
2.  Define the core logic that governs the projected outcomes for the modeled policies
3.  Evaluate a few ways to structure the simulation, including:
4.  allocating and non-allocating approaches
5.  single threaded and mutli-threaded approaches

As will be shown, the number of simulations able to be completed on modern CPU hardware is really remarkable!

```{julia}
#| output: false
using CSV, DataFrames
using MortalityTables, FinanceCore
using Dates
using ThreadsX
using BenchmarkTools
using Random
using CairoMakie
```

## Data and Types

### `@enums` and the `Policy` Type

Our core unit of simulation with be a single life insurance `Policy`. Important characteristics include: the age a policy was issued at, the sex of the insured, and risk class to determine the assumed mortality rate. To make the example more realistic and demonstrate how it might look for a real block of inforce policies, additional fields have been included such as ID (not really used, but a common identifier) and `COLA` which is a cost-of-living-adjustment, used to modify the policy benefit through time. To be clear: the `Policy` type has more fields than will actually be used in the calculations, with the purpose to show how typical fields used in practice might be defined.

Before we define the core `Policy` type, there's a couple of types we might consider defining that would subsequently get used by `Policy`: types representing sex and risk class. A typical approach might be to simply define associated types, like this:

``` julia
abstract type Sex end

struct Male <: Sex end
struct Female <: Sex end
```

Then, if we were to include a sex field in Policy, we could write it like this:

``` julia
struct Policy
    # ... 
    sex::Sex
    # ...
end
```

This would be a totally valid and logical approach! However, high performance is a top priority for this simulation, and therefore this approach would sacrifice being able to keep `Policy` data on the stack instead of the heap. This is because `Sex` is of unknown concrete type, which could be as simple as our definition above (with no fields in `Male` and `Female`) or someone could add a new `Alien` subtype of `Sex` with a number of associated data fields! This is why Julia cannot assume that subtypes of `Sex` will always be a simple Singletons with no associated data.

Instead, we can utilize Enums, which are a sort of lightweight type where the only thing that matters with it is distinguishing between categories. Enums in Base Julia are basically a set of constants grouped together that reference an associated integer.

```{julia}
@enum Sex Female = 1 Male = 2
@enum Risk Standard = 1 Preferred = 2
@enum PaymentMode Annual = 1 Quarterly = 4 Monthly = 12
```

Enums are convenient because it lets us use human-meaningful names for integer-based categories. Julia will also keep track of valid options: we cannot now use anything other than `Female` or `Male` where we have said a `Sex` must be specified.

::: callout-note
There exist Julia packages which are more powerful versions of Enums, essentially leaning into the ability to use the type system instead of just nice names for categorical variables.
:::

Moving on to the definition of the policy itself, here's what that looks like. Note that every field has a type annotation associated with it.

```{julia}
struct Policy
    id::Int
    sex::Sex
    benefit_base::Float64
    COLA::Float64
    mode::PaymentMode
    issue_date::Date
    issue_age::Int
    risk::Risk
end
```

The benefit of the way we have defined it here, using simple bits-types for each field is that our new composite `Policy` type is also a bitstype:

```{julia}
let
    p = Policy(1, Male, 1e6, 0.02, Annual, today(), 50, Standard)

    isbits(p)
end
```

::: callout-note
Type annotations are optional, but providing them is able to coerce the values to be all plain bits (i.e. simple, non-referenced values like arrays are) when the type is constructed. We could have defined `Policy` without the types specified:

``` julia
struct Policy
    id
    sex
    ...
    risk
end
```

Leaving out the annotations here forces Julia to assume that `Any` type could be used for the given field. Having the field be of type `Any` makes the instantiated struct data be stored in the heap, since Julia can't know the size of `Policy` in bits in advance.

We would also find that the un-annotated type is about 50 times slower than the one with annotation due to the need to utilize runtime lookup and reference memory on the heap instead of the stack.
:::

### The Data

To partially illustrate a common workflow, we'll pretend that the data we are interested in comes from a CSV file, which will be defined inline using an `IOBuffer` so that the structure of the source data is clear to the reader. Only two policies will be listed for brevity, but we will duplicate them for simulation purposes later on.

```{julia}
sample_csv_data =
    IOBuffer(
        raw"id,sex,benefit_base,COLA,mode,issue_date,issue_age,risk
         1,M,100000.0,0.03,12,1999-12-05,30,Std
         2,F,200000.0,0.03,12,1999-12-05,30,Pref"
    )
```

We will not load the sample data using a common pattern:

1.  Load the source file into a `DataFrame`
2.  `map` over each row of the dataframe, and return an instantiated `Policy` object
3.  Within the map, apply basic data parsing and translation logic as needed.

```{julia}
policies = let

    # read CSV directly into a dataframe
    df = CSV.read(sample_csv_data, DataFrame) # <1>

    # map over each row and construct an array of Policy objects
    map(eachrow(df)) do row
        Policy(
            row.id,
            row.sex == "M" ? Male : Female,
            row.benefit_base,
            row.COLA,
            PaymentMode(row.mode),
            row.issue_date,
            row.issue_age,
            row.risk == "Std" ? Standard : Preferred,
        )
    end


end
```

1.  `CSV.read("sample_inforce.csv",DataFrame)` could be used if the data really was in a CSV file named `sample_inforce.csv` instead of our demonstration `IOBuffer`.

## Model Assumptions

### Mortality Assumption

MortalityTables.jl provides common life insurance industry tables, and we will use two tables: one each for male and female policies respectively.

```{julia}
mort = Dict(
    Male => MortalityTables.table(988).ultimate, #<1>
    Female => MortalityTables.table(992).ultimate,
)

function mortality(pol::Policy, params)
    return params.mortality[pol.sex]
end
```

1.  `ulitmate` refers to not differentiating the mortality by a 'select' underwriting period, which is common but uncessary for the deomstration in this chapter.

## Model Struture and Mechanics

### Core Model Behavior

The overall flow of the model loop will be as follows:

1.  Determine some initialized values for each policy at the start of the projection.
2.  Step through annual timesteps and simulate whether a death has occurred.
    1.  If a death has occurred, log the benefit paid out.
    2.  If a death has not occurred keep track of the remaining lives inforce and increment policy values.

The code is shown first and then discussion will follow it:

```{julia}
function pol_project!(out, policy, params)
    # some starting values for the given policy
    dur = length(policy.issue_date:Year(1):params.val_date) + 1
    start_age = policy.issue_age + dur - 1
    COLA_factor = (1 + policy.COLA)
    cur_benefit = policy.benefit_base * COLA_factor^(dur - 1)

    # get the right mortality vector
    qs = mortality(policy, params)

    # grab the current thread's id to write to results container 
    # without conflicting with other threads
    tid = Threads.threadid()

    ω = lastindex(qs)

    @inbounds for t in 1:min(params.proj_length, ω - start_age) # <1>

        q = qs[start_age+t] # get current mortality

        if (rand() < q)
            # if dead then just return and don't increment the results anymore
            out.benefits[t, tid] += cur_benefit # <2>
            return
        else
            # pay benefit, add a life to the output count, and increment the benefit for next year
            out.lives[t, tid] += 1
            cur_benefit *= COLA_factor
        end
    end
end
```

1.  `inbounds` turns off bounds-checking, which makes hot loops faster but first write loop without it to ensure you don't create an error (will crash if you have the error without bounds checking)
2.  Note that the loop is iterating down a column (i.e. across rows) for efficiency (since Julia is column-major).

### Inputs and Outputs

#### Inputs

The general approach for non-allocating model runs is to provide a previously instantiated container for the function to write the results to. Here, the incoming argument `out`(put) will be a named tuple with associated matrices as the `lives` and `benefits` fields. We know how many periods the model will simulate for and can therefore size the array appropriately at creation.

Other inputs include: `params` which defines some global-like parameters and `policy` which is a single `Policy` object.

::: callout-note
Note that the unit of the core model logic is a single policy. This simplifies the logic and reduces the chance for error due to needing to code for entire arrays of policies at a single time (as would be the case for array oriented programming style, as described in @sec-array-oriented-styles).
:::

### Threading

The simulations is using a threaded parallelism approach where it could be operating on any of the computer's available threads. Multi-processor (multi-machine) or GPU-based computation would require some modifications see (@sec-parallelization). For the scale and complexity of this example, thread-based parallelism on a single CPU is all one should need for compute.

The threads are handled by distributed the work across threads (this is done by `ThreadsX` in the `foreach` loop below), but we need to write the appropriate place in the matrix so that threads do not compete for the same column in the output data. Therefore, when we create the `lives` and `benefits` matrices we need to have them sized so that the number of rows is the number of projection periods and the number of columns is the number of threads.

### Simulation Control

Parameters for our projection:

```{julia}
params = (
    val_date=Date(2021, 12, 31),
    proj_length=100,
    mortality=mort,
)
```

Having defined the model behavior at the unit of the policy above, we now need to define how the model should iterate over the entire population of interest. Given a vector of `Policy`s in the `policies` argument, the `project` function will:

1.  Create output containers, keeping in mind the projection length and number of threads being used.
2.  Loop over each policy, letting `ThreadsX.foreach` distribute the work across different threads.
3.  Sum up the results across threads via `reduce`.

```{julia}
function project(policies, params)
    threads = Threads.nthreads()
    benefits = zeros(params.proj_length, threads)
    lives = zeros(Int, params.proj_length, threads)
    out = (; benefits, lives)
    ThreadsX.foreach(policies) do pol
        pol_project!(out, pol, params)
    end
    map(x -> vec(reduce(+, x, dims=2)), out) # <1>
end
```

1.  `vec` turns the result into a 1D vector instead of a 1D matrix for later convenience.

## Running the projection

Example of a single projection:

```{julia}
project(repeat(policies, 100_000), params) # <!>
```

1.  `repeat` creates a vector that repeats the two demonstration policies many times.

### Stochastic Projection

This defines a loop to calculate the results `n` times (this is only running the two policies in the sample data `n` times). This is emulating running our population of policies through $n$ stochastic scenarios, similar to what might be done for a risk or pricing exercise.

```{julia}
function stochastic_proj(policies, params, n)

    ThreadsX.map(1:n) do i
        project(policies, params)
    end
end
```

#### Demonstration

We'll simulate the two policies' outcomes 1,000 times and visualize the resulting distribution of claims value:

```{julia}
stoch = stochastic_proj(policies, params, 1000)
```

```{julia}
let
    v = [pv(0.03, s.benefits) for s in stoch]
    hist(v,
        bins=15,
        axis=(
            xlabel="Present Value of Benefits",
            ylabel="Number of scenarios"
        )
    )
end
```

## Benchmarking

Using a 2024 Macbook Air M3 laptop, about 45 million policies able to be stochastically projected per second:

```{julia}
#| column: page-inset-right
policies_to_benchmark = 4_500_000
# adjust the `repeat` depending on how many policies are already in the array
# to match the target number for the benchmark
n = policies_to_benchmark ÷ length(policies)

@benchmark project(p, r) setup = (p = repeat($policies, $n); r = $params)
```

## Conclusion

This example has worked through a recommended pattern of setting up and running a stochastic simulation using a threaded approach to parallelism. The results show that quite a bit of simulation power is available using even consumer laptop hardware!