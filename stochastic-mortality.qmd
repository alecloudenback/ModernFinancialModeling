---
author:
  - name: Alec Loudenback
---

# Stochastic Mortality Projections {#sec-stochastic-mortality}

## Chapter Overview

A term life insurance`\index{term life insurance}`{=latex} policy is used to illustrate: selecting key model features, design tradeoffs between a few different approaches, and a discussion of the performance impacts of the different approaches to parallelism.

```{julia}
#| echo: false
#| output: false
using Pkg
Pkg.activate("env/stochastic_mortality")
Pkg.instantiate()
```

## Introduction

Monte Carlo simulation`\index{Monte Carlo simulation}`{=latex} is common in risk and valuation contexts. This worked example will create a population of term life insurance policies and simulate the associated claims stochastically. For this chapter, the focus is not so much on the outcomes of the model, but instead *how* and *why* the model was chosen to be setup in the way that it is.

The general structure of the example is:

1.  Define the datatypes and sample data
2.  Define the core logic that governs the projected outcomes for the modeled policies
3.  Evaluate a few ways to structure the simulation, including:
    - allocating and non-allocating approaches
    - single threaded and multi-threaded approaches

As will be shown, the number of simulations able to be completed on modern CPU hardware is really remarkable!

```{julia}
#| output: false
using CSV, DataFrames
using MortalityTables, FinanceCore
using Dates
using ChunkSplitters
using BenchmarkTools
using Random
using CairoMakie
```

## Data and Types

### `@enums` and the `Policy` Type

Our core unit of simulation will be a single life insurance `Policy`. Important characteristics include: the age a policy was issued at, the sex of the insured, and risk class to determine the assumed mortality rate. To make the example more realistic and demonstrate how it might look for a real block of inforce policies, additional fields have been included such as ID (not really used, but a common identifier) and `COLA` which is a cost-of-living-adjustment, used to modify the policy benefit through time. To be clear: the `Policy` type has more fields than will actually be used in the calculations, with the purpose to show how typical fields used in practice might be defined.

Before we define the core `Policy` type, there are a couple of types we might consider defining that would subsequently get used by `Policy`: types representing sex and risk class. A typical approach might be to simply define associated types, like this:

``` julia
abstract type Sex end

struct Male <: Sex end
struct Female <: Sex end
```

Then, if we were to include a sex field in Policy, we could write it like this:

``` julia
struct Policy
    # ... 
    sex::Sex
    # ...
end
```

This would be a totally valid and logical approach! However, high performance is a top priority for this simulation, and therefore this approach would sacrifice being able to keep `Policy` data on the stack instead of the heap. This is because `Sex` is of unknown concrete type, which could be as simple as our definition above (with no fields in `Male` and `Female`) or someone could add a new `Alien` subtype of `Sex` with a number of associated data fields! This is why Julia cannot assume that subtypes of `Sex` will always be simple singletons with no associated data.

Instead, we can utilize Enums`\index{enum}`{=latex}, which are a sort of lightweight type where the only thing that matters with it is distinguishing between categories. Enums in Base Julia are basically a set of constants grouped together that reference an associated integer.

```{julia}
@enum Sex Female = 1 Male = 2
@enum Risk Standard = 1 Preferred = 2
@enum PaymentMode Annual = 1 Quarterly = 4 Monthly = 12
```

Enums are convenient because it lets us use human-meaningful names for integer-based categories. Julia will also keep track of valid options: we cannot now use anything other than `Female` or `Male` where we have said a `Sex` must be specified.

::: callout-note
There exist Julia packages which are more powerful versions of Enums, essentially leaning into the ability to use the type system instead of just nice names for categorical variables.
:::

Moving on to the definition of the policy itself, here's what that looks like. Note that every field has a type annotation associated with it.

```{julia}
struct Policy
    id::Int
    sex::Sex
    benefit_base::Float64
    COLA::Float64
    mode::PaymentMode
    issue_date::Date
    issue_age::Int
    risk::Risk
end
```

The benefit of the way we have defined it here, using simple bits-types for each field is that our new composite `Policy` type is also a bitstype:

```{julia}
let
    p = Policy(1, Male, 1e6, 0.02, Annual, today(), 50, Standard)

    isbits(p)
end
```

::: callout-note
Type annotations are optional, but providing them is able to coerce the values to be all plain bits (i.e. simple, non-referenced values like arrays are) when the type is constructed. We could have defined `Policy` without the types specified:

``` julia
struct Policy
    id
    sex
    ...
    risk
end
```

Leaving out the annotations here forces Julia to assume that `Any` type could be used for the given field. Having the field be of type `Any` makes the instantiated struct data be stored in the heap, since Julia can't know the size of `Policy` in bits in advance.

We would also find that the un-annotated type is about 50 times slower than the one with annotation due to the need to utilize runtime lookup and reference memory on the heap instead of the stack.
:::

### The Data

To partially illustrate a common workflow, we'll pretend that the data we are interested in comes from a CSV file, which will be defined inline using an `IOBuffer` so that the structure of the source data is clear to the reader. Only two policies will be listed for brevity, but we will duplicate them for simulation purposes later on.

```{julia}
sample_csv_data =
    IOBuffer(
        raw"id,sex,benefit_base,COLA,mode,issue_date,issue_age,risk
         1,M,100000.0,0.03,12,1999-12-05,30,Std
         2,F,200000.0,0.03,12,1999-12-05,30,Pref"
    );
```

We will now load the sample data using a common pattern:

1.  Load the source file into a `DataFrame`
2.  `map` over each row of the dataframe, and return an instantiated `Policy` object
3.  Within the map, apply basic data parsing and translation logic as needed.

```{julia}
policies = let

    # read CSV directly into a dataframe
    df = CSV.read(sample_csv_data, DataFrame) # <1>

    # map over each row and construct an array of Policy objects
    map(eachrow(df)) do row
        Policy(
            row.id,
            row.sex == "M" ? Male : Female,
            row.benefit_base,
            row.COLA,
            PaymentMode(row.mode),
            row.issue_date,
            row.issue_age,
            row.risk == "Std" ? Standard : Preferred,
        )
    end


end
```

1.  `CSV.read("sample_inforce.csv",DataFrame)` could be used if the data really was in a CSV file named `sample_inforce.csv` instead of our demonstration `IOBuffer`.

## Model Assumptions

### Mortality Assumption

MortalityTables.jl`\index{MortalityTables.jl}`{=latex} provides common life insurance industry tables, and we will use two tables: one each for male and female policies respectively.

```{julia}
mort = Dict(
    Male => MortalityTables.table(988).ultimate, #<1>
    Female => MortalityTables.table(992).ultimate,
)

function mortality(pol::Policy, params)
    return params.mortality[pol.sex]
end
```

1.  `ultimate` refers to not differentiating the mortality by a 'select' underwriting period, which is common but unnecessary for the demonstration in this chapter.

## Model Structure and Mechanics

### Core Model Behavior

The overall flow of the model loop will be as follows:

1.  Determine some initialized values for each policy at the start of the projection.
2.  Step through annual timesteps and simulate whether a death has occurred.
    1.  If a death has occurred, log the benefit paid out.
    2.  If a death has not occurred, keep track of the remaining lives in force and increment policy values.

The code is shown first and then discussion will follow it:

```{julia}
function pol_project!(out, policy, params)
    # some starting values for the given policy
    dur = length(policy.issue_date:Year(1):params.val_date) + 1
    start_age = policy.issue_age + dur - 1
    COLA_factor = (1 + policy.COLA)
    cur_benefit = policy.benefit_base * COLA_factor^(dur - 1)

    # get the right mortality vector
    qs = mortality(policy, params)

    ω = lastindex(qs)

    @inbounds for t in 1:min(params.proj_length, ω - start_age) # <1>

        q = qs[start_age+t] # get current mortality

        if (rand() < q)
            # if dead then just return and don't increment the results anymore
            out.benefits[t] += cur_benefit # <2>
            return
        else
            # pay benefit, add a life to the output count, 
            # and increment the benefit for next year
            out.lives[t] += 1
            cur_benefit *= COLA_factor
        end
    end
end
```

1.  `inbounds` turns off bounds-checking, which makes hot loops faster but first write the loop without it to ensure you don't create an error (will crash if you have the error without bounds checking)
2.  Note that the loop is iterating down a column (i.e. across rows) for efficiency (since Julia is column-major).

### Inputs and Outputs

#### Inputs

The general approach for non-allocating model runs is to provide a previously instantiated container for the function to write the results to. Here, the incoming argument `out`(put) will be a named tuple with associated vectors as the `lives` and `benefits` fields. We know how many periods the model will simulate for and can therefore size the array appropriately at creation.

Other inputs include: `params` which defines some global-like parameters and `policy` which is a single `Policy` object.

::: callout-note
Note that the unit of the core model logic is a single policy. This simplifies the logic and reduces the chance for error due to needing to code for entire arrays of policies at a single time (as would be the case for array oriented programming style, as described in @sec-array-oriented-styles).
:::

### Threading

The simulation uses a threaded parallelism`\index{multi-threading}`{=latex} approach with `ChunkSplitters` `\index{ChunkSplitters.jl}`{=latex} to divide work across available CPU threads. This pattern ensures thread safety`\index{thread safety}`{=latex} by:

1.  Splitting the policy array into chunks, one per thread
2.  Each thread maintains its own local output buffer
3.  Results are safely combined after all threads complete

Multi-processor (multi-machine) or GPU-based computation would require some modifications; see @sec-parallelization. For the scale and complexity of this example, thread-based parallelism on a single CPU is all one should need for compute.

### Simulation Control

Parameters for our projection:

```{julia}
params = (
    val_date=Date(2021, 12, 31),
    proj_length=100,
    mortality=mort,
);
```

Having defined the model behavior at the level of the policy above, we now need to define how the model should iterate over the entire population of interest. Given a vector of `Policy`s in the `policies` argument, the `project` function will:

1.  Create output containers for each thread chunk.
2.  Split work across threads using `ChunkSplitters`, with each thread processing its chunk independently.
3.  Spawn tasks for parallel execution and safely combine results.

```{julia}
function project(policies, params)
    # Split policies into chunks, one per thread
    tasks = map(chunks(policies; n=Threads.nthreads())) do chunk
        Threads.@spawn begin
            # Each thread gets its own output buffer
            thread_out = (
                benefits=zeros(params.proj_length),
                lives=zeros(Int, params.proj_length)
            )
            # Process all policies in this chunk
            for pol in chunk
                pol_project!(thread_out, pol, params)
            end
            thread_out
        end
    end

    # Initialize final output
    output = (
        benefits=zeros(params.proj_length),
        lives=zeros(Int, params.proj_length)
    )

    # Safely combine results from all threads
    for task in tasks
        thread_result = fetch(task)
        output.benefits .+= thread_result.benefits
        output.lives .+= thread_result.lives
    end

    output
end
```

## Running the projection

Example of a single projection:

```{julia}
project(repeat(policies, 100_000), params); # <1>
```

1.  `repeat` creates a vector that repeats the two demonstration policies many times.

### Stochastic Projection

This defines a loop to calculate the results `n` times (this is only running the two policies in the sample data `n` times). This emulates running our population of policies through $n$ stochastic scenarios, similar to what might be done for a risk or pricing exercise.

```{julia}
function stochastic_proj(policies, params, n)
    # Split scenarios into chunks for parallel processing
    tasks = map(chunks(1:n; n=Threads.nthreads())) do chunk
        Threads.@spawn begin
            [project(policies, params) for _ in chunk]
        end
    end

    # Collect all results
    results = []
    for task in tasks
        append!(results, fetch(task))
    end

    results
end
```

#### Demonstration

We'll simulate the two policies' outcomes 1,000 times and visualize the resulting distribution of claims value:

```{julia}
stoch = stochastic_proj(policies, params, 1000);
```

```{julia}
let
    v = [pv(0.05, s.benefits) for s in stoch] # <1>
    hist(v,
        bins=15,
        axis=(
            xlabel="Present Value of Benefits",
            ylabel="Number of scenarios"
        )
    )
end
```

1. The discount rate (5%) exceeds the COLA (3%), so the timing of death affects the present value. Earlier deaths produce higher present values because the discounting effect dominates the benefit growth: while early benefits are smaller, they are discounted less, and the net effect favors earlier payouts.

## Benchmarking

Many millions of policies are able to be stochastically projected per second using a laptop computer[^stochastic-mortality-1]:

[^stochastic-mortality-1]: See the Colophon section in the Introduction for details on the hardware used to render this book.

```{julia}
#| column: page-inset-right
policies_to_benchmark = 10_000_000
# adjust the `repeat` depending on how many policies are already in the array
# to match the target number for the benchmark
n = policies_to_benchmark ÷ length(policies)

@benchmark project(p, r) setup = (p = repeat($policies, $n); r = $params)
```

## Conclusion

This example has worked through a recommended pattern of setting up and running a stochastic simulation using a threaded approach to parallelism with proper thread safety guarantees. The `ChunkSplitters` pattern ensures that:

-   Each thread works on its own data without conflicts
-   Results are safely combined after parallel execution completes
-   The code is maintainable and follows Julia best practices

The results show that quite a bit of simulation power is available using even consumer laptop hardware!
