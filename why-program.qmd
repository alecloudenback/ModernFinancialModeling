---
author:
  - name: Alec Loudenback
---

# Why Program?

> “Humans are allergic to change. They love to say, ‘We’ve always done it this way.’ I try to fight that. That’s why I have a clock on my wall that runs counterclockwise.” - Grace Hopper (1987)

## Chapter Overview

Why should a financial professional learn to program? Because it will improve your capabilities, your enjoyment of the work, and—not incidentally—your career prospects.

## Introduction

The financial sector is undergoing a profound transformation. In an era defined by big data, (pseudo) artificial intelligence`\index{artificial intelligence}`{=latex}, and rapid technological advancement, the traditional boundaries of finance are expanding and blurring. From Wall Street to Main Street, from global investment banks to local credit unions, technology is reshaping how financial services are delivered, how risks are managed, and how decisions are made.

This digital revolution is not just changing the tools we use; it's fundamentally altering the skills required to succeed in finance. In the past, a strong foundation in mathematics, economics, and financial theory was sufficient for most roles in the industry. Today, these skills, while still crucial, are increasingly being augmented (and, in some cases, superseded) by technological proficiency.

Programming skills sit at the center of this shift. In the early computer era in finance, the differentiating skill was the ability to use digital computing, data processing, and calculation engines to automate, analyze, and report on the business. These skills required low-level programming, and the success of those early programs is evident in their legacy: many of them are still running in the 2020s!

At some point, due to regulatory pressures, attempts at organizational efficiencies, or management decision making, the skill of programming became highly specialized and most financial professionals (investment analysts, actuaries, accountants, etc.) became relegated to being "business users", utilizing either Microsoft Excel or a proprietary third-party software to accomplish their responsibilities. The reasons for this were not totally wrong, even in retrospect.

At some point, with an increasingly complex stack of software sitting between the developer and the hardware, combined with the proliferation of computer security risks, it made some sense that many financial developers were pushed out of the programming trade. Instead, specialized, separate business and IT units were developed. Of course, this led to many inefficiencies and the pendulum is now swinging back the other way.

What's changed that's enabling financial professionals to re-engage with the powerful tools that programming provides? Some reasons include:

1.  **Code management tools**. GitHub`\index{GitHub}`{=latex} and other version control`\index{version control}`{=latex} systems provide best-in-class ways of managing codebase changes and collaboration. Tools exist to scan repositories for leaking secrets, security vulnerabilities, and dependency management.
2.  **Increasingly accessible development**. Originally, very few layers of complexity existed between the written code and running it on the mainframe. Over time, drivers, operating systems, networking, dependencies, and compilers made development more complex. Today, languages, libraries, code editors, and deployment tools have smoothed many of these frictions.
3.  **Competitive Pressures**. An increasingly commoditized financial product with evermore competition has led to a need to improve efficiency of manufacturing and selling financial products. Having a business developer is a lot more efficient than a business user who needs to get an IT developer to implement something. Further, pressures from outside the financial sector abound: It's easier to teach a tech developer enough to be successful in a finance role than it is to teach a finance professional development skills.
4.  **Regulatory and Risk Demands**. Pressures that previously motivated the move to proprietary software for modeling included regulatory reporting, internal risk metrics, and management performance evaluation. However, companies are realizing that their unique products, risk frameworks, preferred management measurements, and employee potential mean that having a bespoke internal model is seen as a key capability. Many regulatory frameworks also encourage the use of a bespoke model, which is a particularly attractive option especially for those who view the given regulatory framework as inappropriately reflecting their own business and risk profile.

Whether you're an investment banker modeling complex derivatives, an actuary calculating insurance risks, a financial planner optimizing client portfolios, or a risk manager stress-testing scenarios, the ability to code is becoming as fundamental as the ability to use a spreadsheet was a generation ago. To remain competitive, adaptable, and effective in the evolving landscape of finance, professionals must embrace programming as a core skill.

::: callout-note
One subset of business analysts that *did not* start to migrate away from development as a strategic part of their value were "quants" or quantitative analysts`\index{quantitative analysts}`{=latex} who heavily utilized programming skills to develop unique products, trading strategies, modeling frameworks, and risk engines. This book is not really for that set of people and is instead geared towards the mass of financial professionals who want to get some of the benefits of the tools that the quants have been using for years. Quants may find value here in adapting some of their existing knowledge with the concepts and capabilities that Julia enables.
:::

As we delve into this topic, keep in mind that learning to code is not about replacing traditional financial acumen—it's about augmenting and enhancing it. It's about equipping yourself with the tools to tackle the complex, data-driven challenges of modern finance. In short, it's about future-proofing your career in an industry that is increasingly defined by its ability to innovate and adapt to technological change.

### Market Forces

Today, there is a trend toward technological value-creation that is evident across many traditional sectors. Tesla claims that it's a technology company; Amazon is the #1 product retailer because of its vehement focus on internal information sharing[^why-program-1]; airlines are so dependent on their systems that the skies become quieter on the rare occasion that their computers give way. Why are companies involved in *things* (cars, shopping) and *physical services* (flights) more focused on improving their technological operations than insurance companies, *whose very focus is information-based*? **The market has rewarded those who have prioritized their internal technological solutions.**

[^why-program-1]: [Have you had your Bezos moment? What you can learn from Amazon](https://www.cio.com/article/3218667/have-you-had-your-bezos-moment-what-you-can-learn-from-amazon.html).

Commoditized investing services and challenging yield environments have eroded the comparative advantage of "managing money." Spread compression and the explosion of consumer-oriented investment services mean that competition now focuses on efficiently managing an asset or policy's entire lifecycle (digitally), performing more real-time analysis of experience and risk, and handling growing product and regulatory complexity.

These are problems that have technological solutions and are waiting for insurance company adoption.

Companies that treat data like coordinates on a grid (spreadsheets) *will get left behind*. Two main hurdles have prevented technology companies from breaking into insurance and traditional finance:

1.  High regulatory barriers to entry, and
2.  Difficulty in selling complex insurance products without traditional distribution.

Once those two walls are breached, traditional finance companies without a strong technology core will struggle to keep up. The key to thriving is not just adding "developers" to an organization; it will require **getting domain experts like financial modelers to be an integral part of the technology transformation.**

## Why Programming Matters Now

Programming is becoming as fundamental for financial professionals as spreadsheet skills were a generation ago. Here's why:

1.  **Enhanced Analysis Capabilities**: Programming allows for more complex analyses, handling of larger datasets, and application of advanced statistical and machine learning techniques.`\index{data science}`{=latex}

2.  **Automation and Efficiency**: Repetitive tasks can be automated`\index{automation}`{=latex}, freeing up time for more value-added activities.

3.  **Customization**: Bespoke solutions can be developed to address unique business needs, risk frameworks, and regulatory requirements.

4.  **Data Handling**: As data volumes grow, programming provides tools to efficiently process, analyze, and derive insights from vast amounts of information.

5.  **Integration**: Programming skills enable better integration across different systems and data sources, providing a more holistic view of financial operations.

6.  **Competitive Edge**: In an increasingly technology-driven industry, programming skills can be a significant differentiator.

It's now commonly accepted that to gather insights from your data, you need to know how to code. Modeling and valuation needs, too, are often better suited to customized solutions. Let's not stop at data science when learning how to solve problems with a computer.

## The Spectrum of Programming in Finance

It's important to note that becoming proficient in programming doesn't mean you need to become a full-time software developer. There's a spectrum of programming skills that can benefit financial professionals:

1.  **Basic Scripting**: Automating repetitive tasks in Excel or other tools.
2.  **Data Analysis**: Using languages like Python or R for statistical analysis and visualization.
3.  **Model Building**: Developing financial models or risk assessment tools.
4.  **Full-Scale Application Development**: Creating more complex applications for internal use or client-facing solutions.

## Artificial Intelligence (AI) \index{Artificial Intelligence (AI)}`{=latex}

One tantalizing path to contemplate is avoiding *really* learning how to code. Between artificial intelligence (AI) solutions being developed and low-code offerings, is there really a need to learn the fundamentals of coding? We argue emphatically that there is. Coding is not about mechanically typing out lines in an editor --- it is a discipline for thinking clearly about complex problems. The act of translating a financial model into code forces you to make every assumption explicit, every edge case visible, and every dependency traceable. AI can't do that *for* you; it can only do it *instead of* you, and the distinction matters.

This is more than philosophy --- it's supported by experimental evidence. In a study by Anthropic, 52 mostly junior software engineers with Python experience were given coding tasks. Half got AI assistance, half didn't [@shen2026aiskills]. Afterward, both groups took a quiz without AI. The AI-assisted group scored 17% lower --- roughly two letter grades --- with the biggest gap in debugging skills. Meanwhile, the AI users completed tasks only about two minutes faster on average, a difference that wasn't statistically significant. In other words: measurable skill loss for negligible speed gain.

The most revealing part is that *how* people used AI mattered enormously. The researchers identified six distinct interaction patterns. Users who engaged in "AI delegation" (copy-pasting without reading) or "iterative debugging" (repeatedly pasting errors back) had the lowest quiz scores. Those who adopted "conceptual inquiry" (asking how concepts work before coding) or "hybrid explanation" (asking AI to generate and explain code) maintained learning outcomes comparable to manual coders. The implication is clear: AI is a powerful *learning accelerant* when used to deepen understanding, but a *skill eroder* when used to bypass it.

This has direct implications for financial modeling teams. Developers who relied on AI encountered fewer errors during the task itself but were less able to identify and resolve issues independently afterward, while those without AI encountered more errors during the task, which appeared to strengthen their understanding. In a field where a missed edge case in a valuation model can move millions of dollars, the ability to debug, reason about, and defend your own code is not optional.

A somewhat sobering implication for agentic AI: the researchers think that while agentic AI might improve productivity on short run tasks, it may reduce the development of critical skills in the long run. If AI is doing the work, users may not be learning the underlying concepts and problem-solving skills that are essential for growth and adaptability in their field.

The current generation of AI`\index{Artificial Intelligence (AI)}`{=latex} is also fundamentally limited in ways that matter for modeling. As Yann LeCun, Meta's Chief AI Scientist, notes, current Large Language Models (LLMs)`\index{Large Language Models (LLMs)}`{=latex} lack a fundamental grasp of logic and causality. They "cannot reason in any reasonable definition of the term and cannot plan... hierarchically," making them powerful assistants for syntax and boilerplate but unreliable architects for the complex, logical structures required in financial modeling [@ftLeCun]. An LLM can generate a Monte Carlo loop, but it cannot tell you whether the model's assumptions are appropriate for the risk you're trying to measure.

The bottom line: AI will play an important and growing role *supporting* modelers --- lowering syntactical hurdles ("in VBA I would do it like this, but in Julia how do I do X, Y, or Z?"), generating boilerplate, and providing algorithmic scaffolding. What it will not replace is the core value a modeler brings: skepticism, creative thinking, understanding of company and market dynamics, and the capability to grasp the broader architecture and conceptual aspects of a model. Learning to program well makes you a *better* user of AI tools, not a redundant one.

::: {.callout-note}
## Julia and AI Code Generation

Counterintuitively, Julia --- despite having a far smaller training corpus than Python --- consistently performs as well or better in LLM code generation benchmarks. In a study evaluating ChatGPT 4 across 19 programming languages, Julia achieved the highest success rate at 81.5%, while C++ had the lowest at 7.3% [@buscemi2023codegen]. The MultiPL-T project, which fine-tuned open-source Code LLMs on low-resource languages including Julia, found that these models outperformed other open Code LLMs on the MultiPL-E benchmark.

Why does a language with less training data produce better AI-generated code? The leading explanation is *syntactic consistency*. Julia has a uniform standard library API, one canonical way to do most things, and a corpus skewed toward expert-written packages rather than introductory exercises. Chris Rackauckas (MIT, author of DifferentialEquations.jl) observed that LLM-generated Python code for his diffeqpy library had dramatically more errors than the equivalent Julia code --- particularly in the same spots where new students struggle: API inconsistencies, multiple ways to express basic operations, and fragmented ecosystems. In Julia, `rand` works the same way whether you're sampling a scalar, a distribution, or a custom type. That consistency helps humans *and* machines.

The practical takeaway: if you're going to use AI-assisted coding (and you should), Julia's design means you'll spend less time fixing the AI's output and more time on the modeling problem itself.
:::

## Low Code

A similarly fraught path is using low-code solutions. Low-code is inherently limiting and locks you into a particular vendor's proprietary ecosystem. If you know enough about what you're trying to do to state it clearly in plain English, you're most of the way to programming in a full coding solution (AI can help bridge this gap). As soon as you hit a limitation ("I'd like to use XYZ optimization algorithm at each timestep"), you're reliant on the vendor to implement that option. Further, you're outsourcing important inner-workings of the model to someone else and not building that expertise yourself or in-house.

## The 10x Modeler

Increasingly complex business needs will highlight a large productivity difference between a financial modeler who can code and one who can't—simply because the former can react, create, synthesize, and model faster. From transforming administration extracts to summarizing valuation output to analyzing data in ways spreadsheets simply can't handle, you can become a "**10x Modeler**"`\index{10x modeler}`{=latex}[^why-program-2].

[^why-program-2]: The term '10x developer' originates from the technology sector to describe an engineer considered to be an order of magnitude more productive than their peers. This book adapts the concept to the domain of financial modeling.

::: callout-note
In the technology sector, a 10x developer is a term for a software engineer who is an order of magnitude more productive, creative, or capable than a typical peer. Here, we extend the notion to developers of financial models.
:::

Working within a vendor's graphical user interface (GUI) makes you a consumer of their modeling tool. Writing your own model in code makes you an architect of the solution. This is the difference between surface-level familiarity and full command over the analysis and concepts involved—with the flexibility to do what your software can't.

Your current software might be able to perform the first layer of analysis, but be at a loss when you want to take it a step further. Tasks like visualizations, sensitivity analysis, summary statistics, stochastic analysis, or process automation, when done programmatically, are often just a few lines of additional code over and above the primary model.

Don't abandon commercial tools prematurely. Complement them with code to break out of constraints and integrate their outputs into broader pipelines. But the ability to supplement and break out of the modeling box has become an increasingly important part of most professionals' work, and this trend is accelerating.

Code-based solutions can also leverage the entire technology sector's progress to solve problems that are *hard* otherwise: scalability, data workflows, integration across functional areas, version control, model change governance, reproducibility, and more.

Thirty to forty years ago, there were no vendor-supplied modeling solutions—you had no choice but to build models internally. That shifted with the advent of vendor-supplied solutions. Today, it's never been better for companies to leverage open and inner source to support custom modeling, risk analysis and monitoring, and reporting workflows.

::: callout-note
**Open source**`\index{open source}`{=latex} refers to software whose source code is freely available for anyone to view, modify, and distribute. It promotes collaboration, transparency, and innovation by allowing developers worldwide to contribute to and improve the codebase. Open source projects often benefit from diverse perspectives and rapid development cycles, resulting in robust and widely-adopted solutions.

**Inner source**`\index{inner source}`{=latex} applies open source principles within a single organization. It encourages internal collaboration, code sharing, and transparency across different teams or departments. By adopting inner source practices, companies can reduce duplication of effort, improve code quality, and foster a culture of knowledge sharing. This approach can lead to more efficient development processes and better utilization of internal resources.
:::

It is said that you cannot fully conceptualize something unless your language has a word for it. Similar to spoken language, you may find that breaking out of spreadsheet coordinates (and even a dataframe-centric view of the world) reveals different questions to ask and enables innovative ways to solve problems. In this way, you reward your intellect while building more meaningful and relevant models and analysis.

## Risk Governance

Code-based workflows are highly conducive to risk governance`\index{risk governance}`{=latex} frameworks as well. If a modern software project has all of the following benefits, then why not a modern insurance product and associated processes?

- Access control, reviews, and approvals
- Versioning, environment pinning, and reproducibility
- Automated testing and continuous validation
- Transparent design and documentation
- Fewer manual interventions and lower user error
- Monitoring, logging, and audit trails
- Clear interfaces to other processes (e.g., APIs, schedulers)
- Collaboration at scale via modern dev tooling

These aspects of business processes are what technology companies *excel* at. There is a litany of highly robust, battle-tested tools used in the information services sectors. This book will introduce much of this to the financial professional (specifically @sec-software-principles, @sec-julia-writing, and @sec-julia-sharing).

## Managing and Leading the Transformation

For managers, literacy in modern analytical tooling is a spectrum. Even senior leaders benefit from hands-on familiarity with how models are designed, tested, and deployed.

The skills that make good programmers—decomposing problems, designing abstractions, iterating—are also core leadership skills. They enable you to articulate a target operating model rather than simply manage current constraints. When you're skilled at pulling apart a problem or process into constituent parts and designing optimal solutions... that's a core attribute of leadership as well as the most essential skill in programming. This perspective also enables a vision of where the organization *should be* instead of where it is now.

The skillset described herein is as important an aspect of career development as mathematical ability, project collaboration, or financial acumen.

## Outlook

Competitiveness increasingly depends on modernization. This will not come solely from large black‑box packages but from domain experts who can encode firm‑specific expertise into transparent, testable, and integrated systems—faster and more robustly than the competition.